{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/Users/paritashah/Desktop/College/Year3/Term2/BigData/finalproject/CorrectionalAnalysis/38492-0003-Data.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['MAND_PRISREL_YEAR', 'PROJ_PRISREL_YEAR', 'PARELIG_YEAR'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m df \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mOFFGENERAL \u001b[39m!=\u001b[39m \u001b[39m9\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[39m# drop columns with mostly missing information \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mMAND_PRISREL_YEAR\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mPROJ_PRISREL_YEAR\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mPARELIG_YEAR\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     10\u001b[0m \u001b[39m# remove unknown admission year datapoints\u001b[39;00m\n\u001b[1;32m     11\u001b[0m df \u001b[39m=\u001b[39m df[df\u001b[39m.\u001b[39mADMITYR \u001b[39m!=\u001b[39m \u001b[39m9999\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/frame.py:5388\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5240\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m   5241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m   5242\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5249\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5250\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5251\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5252\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5253\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5386\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5387\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5388\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5389\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5390\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5391\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5392\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5393\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5394\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5395\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5396\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/generic.py:4505\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4503\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4504\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4505\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4507\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4508\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/generic.py:4546\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4544\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4545\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4546\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4547\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4549\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4550\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/pandas/core/indexes/base.py:6975\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6973\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6974\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6975\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6976\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6977\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['MAND_PRISREL_YEAR', 'PROJ_PRISREL_YEAR', 'PARELIG_YEAR'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# remove unknown education levels\n",
    "df = df[df.EDUCATION != 9]\n",
    "# remove unkown and other prison admission types\n",
    "df = df[df.ADMTYPE != 9]\n",
    "df = df[df.ADMTYPE != 3]\n",
    "# remove unkonwn general offense categories\n",
    "df = df[df.OFFGENERAL != 9]\n",
    "# drop columns with mostly missing information \n",
    "df = df.drop(columns=['MAND_PRISREL_YEAR', 'PROJ_PRISREL_YEAR', 'PARELIG_YEAR'])\n",
    "# remove unknown admission year datapoints\n",
    "df = df[df.ADMITYR != 9999]\n",
    "# remove unknown maximum sentence length datapoints\n",
    "df = df[df.SENTLGTH != 9]\n",
    "# remove unknown offense detail datapoints\n",
    "df = df[df.OFFDETAIL != 99]\n",
    "# remove unknown race datapoints\n",
    "df = df[df.RACE != 9]\n",
    "# remove unknown age at admission datapoints \n",
    "df = df[df.AGEADMIT != 9]\n",
    "# remove unknown release year datapoints\n",
    "df = df[df.RELYR != 9999]\n",
    "# remove unknown and other release type datapoints\n",
    "df = df[df.RELTYPE != 9]\n",
    "df = df[df.RELTYPE != 3]\n",
    "# remove unknown age at release datapoints\n",
    "df = df[df.AGERLSE != 0]\n",
    "# remove TIMESRVD_REL \n",
    "df = df.drop(columns=['TIMESRVD_REL'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "# save dataframe as csv called prisonData1.csv\n",
    "df.to_csv('prisonData1.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with each key is the state code, and the value is the number of inmates\n",
    "fips_codes = [1, 2, 4, 5, 6, 8, 9, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56]\n",
    "state_codes = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"C0\", \"CT\", \"DC\", \"FL\", \"GA\", \"HI\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\n",
    "detailed_offense = [\"murder\", \"negligent manslaugher\", \"rape/SA\", \"robbery\", \"assault\", \"other violent\", \"burglary\", \"larceny\", \"motor vehicle theft\", \"fraud\", \"other property\", \"drugs\", \"public order\", \"unspecified\"]\n",
    "races = [\"white\", \"black\", \"hispanic\", \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m races \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mblack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhispanic\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mother\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[39m# create a new dataframe that is a copy of the original dataframe\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m one_hot_df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m     10\u001b[0m \u001b[39m# for each state code in state_codes, add a column to the dataframe with the state code\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m state \u001b[39min\u001b[39;00m state_codes:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# create a new dataframe that is a copy of the original dataframe\n",
    "one_hot_df = df.copy()\n",
    "\n",
    "# for each state code in state_codes, add a column to the dataframe with the state code\n",
    "for state in state_codes:\n",
    "    one_hot_df[state] = 0\n",
    "\n",
    "# for each offense in detailed_offenses, add a column to the dataframe \n",
    "for offense in detailed_offense:\n",
    "    one_hot_df[offense] = 0\n",
    "\n",
    "# for each race, add a column to the dataframe\n",
    "for race in races:\n",
    "    one_hot_df[race] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each row, add a new column for each state code using .apply\n",
    "for index, state in enumerate(state_codes):\n",
    "    code = fips_codes[index]\n",
    "    one_hot_df[state] = one_hot_df.apply(lambda row: 1 if row['STATE'] == code else 0, axis=1)\n",
    "\n",
    "for index, race in enumerate(races):\n",
    "    code = index + 1\n",
    "    one_hot_df[race] = one_hot_df.apply(lambda row: 1 if row['RACE'] == code else 0, axis=1)\n",
    "\n",
    "for index, offense in enumerate(detailed_offense):\n",
    "    code = index + 1\n",
    "    one_hot_df[offense] = one_hot_df.apply(lambda row: 1 if row['OFFDETAIL'] == code else 0, axis=1)\n",
    "\n",
    "# # save the dataframe to a csv file as oneHotDfAllCols.csv\n",
    "one_hot_df.to_csv('oneHotDfAllCols.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new csv file from oneHotDfAllCols.csv only inlcuding data from states we are interested in \n",
    "one_hot_df = pd.read_csv(\"OneHotDfAllCols.csv\")\n",
    "one_hot_df.drop(columns=['STATE', 'RACE', 'OFFDETAIL', 'ADMTYPE','OFFGENERAL','ADMITYR','RELYR','RELTYPE','AGERLSE','TIMESRVD','Unnamed: 0'], inplace=True)\n",
    "\n",
    "one_hot_df_texas = one_hot_df.copy()\n",
    "one_hot_df_texas = one_hot_df_texas[one_hot_df_texas.TX == 1]\n",
    "one_hot_df_texas.drop(columns=state_codes, inplace=True)\n",
    "one_hot_df_texas.to_csv('oneHotDfTexas.csv', index=True)\n",
    "\n",
    "one_hot_df_illinois = one_hot_df.copy()\n",
    "one_hot_df_illinois = one_hot_df_illinois[one_hot_df_illinois.IL == 1]\n",
    "one_hot_df_illinois.drop(columns=state_codes, inplace=True)\n",
    "one_hot_df_illinois.to_csv('oneHotDfIllinois.csv', index=True)\n",
    "\n",
    "one_hot_df_florida = one_hot_df.copy()\n",
    "one_hot_df_florida = one_hot_df_florida[one_hot_df_florida.FL == 1]\n",
    "one_hot_df_florida.drop(columns=state_codes, inplace=True)\n",
    "one_hot_df_florida.to_csv('oneHotDfFlorida.csv', index=True)\n",
    "\n",
    "one_hot_df_newyork = one_hot_df.copy()\n",
    "one_hot_df_newyork = one_hot_df_newyork[one_hot_df_newyork.NY == 1]\n",
    "one_hot_df_newyork.drop(columns=state_codes, inplace=True)\n",
    "one_hot_df_newyork.to_csv('oneHotDfNewYork.csv', index=True)\n",
    "\n",
    "one_hot_df_nc = one_hot_df.copy()\n",
    "one_hot_df_nc = one_hot_df_nc[one_hot_df_nc.NC == 1]\n",
    "one_hot_df_nc.drop(columns=state_codes, inplace=True)\n",
    "one_hot_df_nc.to_csv('oneHotDfNC.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
